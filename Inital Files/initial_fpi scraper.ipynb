{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e519133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-10 16:06:04,320 - INFO - ====== WebDriver manager ======\n",
      "2026-02-10 16:06:05,315 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2026-02-10 16:06:05,823 - INFO - Get LATEST chromedriver version for google-chrome\n",
      "2026-02-10 16:06:06,318 - INFO - Driver [C:\\Users\\patel\\.wdm\\drivers\\chromedriver\\win64\\144.0.7559.133\\chromedriver-win32/chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: 31-Jan-2025\n",
      "Failed 2025-01: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 28-Feb-2025\n",
      "Failed 2025-02: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 31-Mar-2025\n",
      "Failed 2025-03: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 30-Apr-2025\n",
      "Failed 2025-04: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 31-May-2025\n",
      "Failed 2025-05: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 30-Jun-2025\n",
      "Failed 2025-06: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 31-Jul-2025\n",
      "Failed 2025-07: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 31-Aug-2025\n",
      "Failed 2025-08: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 30-Sep-2025\n",
      "Failed 2025-09: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 31-Oct-2025\n",
      "Failed 2025-10: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 30-Nov-2025\n",
      "Failed 2025-11: Excel file format cannot be determined, you must specify an engine manually.\n",
      "Fetching: 31-Dec-2025\n",
      "Failed 2025-12: Excel file format cannot be determined, you must specify an engine manually.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No data collected",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 134\u001b[39m\n\u001b[32m    131\u001b[39m driver.quit()\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_equity_data:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo data collected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m final_df = pd.concat(all_equity_data, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    138\u001b[39m final_df.drop_duplicates(\n\u001b[32m    139\u001b[39m     subset=[\u001b[33m\"\u001b[39m\u001b[33mReporting Date\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDebt/Equity\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mInvestment Route\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    140\u001b[39m     inplace=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    141\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: No data collected"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ================= CONFIG =================\n",
    "\n",
    "URL = \"https://www.fpi.nsdl.co.in/web/Reports/Archive.aspx\"\n",
    "\n",
    "START_YEAR = 2025\n",
    "CUTOFF_YEAR = 2026\n",
    "END_DATE = datetime.today()\n",
    "\n",
    "DOWNLOAD_DIR = os.path.abspath(\"downloads\")\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# ================= SELENIUM SETUP =================\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "chrome_options.add_experimental_option(\n",
    "    \"prefs\",\n",
    "    {\n",
    "        \"download.default_directory\": DOWNLOAD_DIR,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"directory_upgrade\": True,\n",
    "        \"safebrowsing.enabled\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=chrome_options\n",
    ")\n",
    "\n",
    "# ================= HELPERS =================\n",
    "\n",
    "def wait_and_rename_file(report_date, before_files, timeout=60):\n",
    "    end_time = time.time() + timeout\n",
    "    while time.time() < end_time:\n",
    "        after_files = set(os.listdir(DOWNLOAD_DIR))\n",
    "        new_files = after_files - before_files\n",
    "\n",
    "        for f in new_files:\n",
    "            if f.endswith((\".csv\", \".xls\")):\n",
    "                old_path = os.path.join(DOWNLOAD_DIR, f)\n",
    "                ext = os.path.splitext(f)[1]\n",
    "                new_path = os.path.join(\n",
    "                    DOWNLOAD_DIR, f\"nsdl_fpi_{report_date}{ext}\"\n",
    "                )\n",
    "                os.rename(old_path, new_path)\n",
    "                return new_path\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    raise TimeoutError(\"Download not detected\")\n",
    "\n",
    "def set_date_and_download(date_obj):\n",
    "    date_ui = date_obj.strftime(\"%d-%b-%Y\")\n",
    "    date_file = date_obj.strftime(\"%Y-%m-%d\")\n",
    "    print(\"Fetching:\", date_ui)\n",
    "\n",
    "    before_files = set(os.listdir(DOWNLOAD_DIR))\n",
    "\n",
    "    date_input = driver.find_element(By.ID, \"txtDate\")\n",
    "    driver.execute_script(\"arguments[0].removeAttribute('disabled')\", date_input)\n",
    "    date_input.clear()\n",
    "    date_input.send_keys(date_ui)\n",
    "\n",
    "    driver.execute_script(\n",
    "        \"document.getElementById('hdnDate').value = arguments[0]\",\n",
    "        date_ui\n",
    "    )\n",
    "\n",
    "    driver.find_element(By.ID, \"btnSubmit1\").click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    driver.find_element(By.ID, \"btnExcel\").click()\n",
    "\n",
    "    file_path = wait_and_rename_file(date_file, before_files)\n",
    "\n",
    "    if file_path.endswith(\".csv\"):\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        return pd.read_excel(file_path)\n",
    "\n",
    "# ================= SCRAPING =================\n",
    "\n",
    "driver.get(URL)\n",
    "time.sleep(3)\n",
    "\n",
    "all_equity_data = []\n",
    "\n",
    "# -------- 2000–2009 : monthly last trading day --------\n",
    "\n",
    "for year in range(START_YEAR, CUTOFF_YEAR):\n",
    "    for month in range(1, 13):\n",
    "        last_day = datetime(year, month, 1) + timedelta(days=32)\n",
    "        last_day = last_day.replace(day=1) - timedelta(days=1)\n",
    "\n",
    "        try:\n",
    "            df = set_date_and_download(last_day)\n",
    "            equity_df = df[df[\"Debt/Equity\"].str.contains(\"Equity\", na=False)].copy()\n",
    "            all_equity_data.append(equity_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed {year}-{month:02d}: {e}\")\n",
    "\n",
    "# -------- 2010–today : WEEKLY (Fridays only) --------\n",
    "\"\"\"\n",
    "current = datetime(CUTOFF_YEAR, 1, 1)\n",
    "\n",
    "while current <= END_DATE:\n",
    "    if current.weekday() == 4:  # Friday\n",
    "        try:\n",
    "            df = set_date_and_download(current)\n",
    "            equity_df = df[df[\"Debt/Equity\"].str.contains(\"Equity\", na=False)].copy()\n",
    "            all_equity_data.append(equity_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed {current.strftime('%Y-%m-%d')}: {e}\")\n",
    "\n",
    "    current += timedelta(days=1)\n",
    "\"\"\"\n",
    "# ================= FINAL CLEAN =================\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "if not all_equity_data:\n",
    "    raise RuntimeError(\"No data collected\")\n",
    "\n",
    "final_df = pd.concat(all_equity_data, ignore_index=True)\n",
    "\n",
    "final_df.drop_duplicates(\n",
    "    subset=[\"Reporting Date\", \"Debt/Equity\", \"Investment Route\"],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "final_df.sort_values(\"Reporting Date\", inplace=True)\n",
    "final_df.to_csv(\"fii_equity_2000_to_today.csv\", index=False)\n",
    "\n",
    "print(\"Done. Saved to fii_equity_2000_to_today.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f38d7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement glob (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for glob\n"
     ]
    }
   ],
   "source": [
    "!pip install glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1560fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: nsdl_fpi_2000-01-31.xls\n",
      "Processed: nsdl_fpi_2000-02-29.xls\n",
      "Processed: nsdl_fpi_2000-03-31.xls\n",
      "Processed: nsdl_fpi_2000-04-30.xls\n",
      "Processed: nsdl_fpi_2000-05-31.xls\n",
      "Processed: nsdl_fpi_2000-06-30.xls\n",
      "Processed: nsdl_fpi_2000-07-31.xls\n",
      "Processed: nsdl_fpi_2000-08-31.xls\n",
      "Processed: nsdl_fpi_2000-09-30.xls\n",
      "Processed: nsdl_fpi_2000-10-31.xls\n",
      "Processed: nsdl_fpi_2000-11-30.xls\n",
      "Processed: nsdl_fpi_2000-12-31.xls\n",
      "Processed: nsdl_fpi_2001-01-31.xls\n",
      "Processed: nsdl_fpi_2001-02-28.xls\n",
      "Processed: nsdl_fpi_2001-03-31.xls\n",
      "Processed: nsdl_fpi_2001-04-30.xls\n",
      "Processed: nsdl_fpi_2001-05-31.xls\n",
      "Processed: nsdl_fpi_2001-06-30.xls\n",
      "Processed: nsdl_fpi_2001-07-31.xls\n",
      "Processed: nsdl_fpi_2001-08-31.xls\n",
      "Processed: nsdl_fpi_2001-09-30.xls\n",
      "Processed: nsdl_fpi_2001-10-31.xls\n",
      "Processed: nsdl_fpi_2001-11-30.xls\n",
      "Processed: nsdl_fpi_2001-12-31.xls\n",
      "Processed: nsdl_fpi_2002-01-31.xls\n",
      "Processed: nsdl_fpi_2002-02-28.xls\n",
      "Processed: nsdl_fpi_2002-03-31.xls\n",
      "Processed: nsdl_fpi_2002-04-30.xls\n",
      "Processed: nsdl_fpi_2002-05-31.xls\n",
      "Processed: nsdl_fpi_2002-06-30.xls\n",
      "Processed: nsdl_fpi_2002-07-31.xls\n",
      "Processed: nsdl_fpi_2002-08-31.xls\n",
      "Processed: nsdl_fpi_2002-09-30.xls\n",
      "Processed: nsdl_fpi_2002-10-31.xls\n",
      "Processed: nsdl_fpi_2002-11-30.xls\n",
      "Processed: nsdl_fpi_2002-12-31.xls\n",
      "Processed: nsdl_fpi_2003-01-31.xls\n",
      "Processed: nsdl_fpi_2003-02-28.xls\n",
      "Processed: nsdl_fpi_2003-03-31.xls\n",
      "Processed: nsdl_fpi_2003-04-30.xls\n",
      "Processed: nsdl_fpi_2003-05-31.xls\n",
      "Processed: nsdl_fpi_2003-06-30.xls\n",
      "Processed: nsdl_fpi_2003-07-31.xls\n",
      "Processed: nsdl_fpi_2003-08-31.xls\n",
      "Processed: nsdl_fpi_2003-09-30.xls\n",
      "Processed: nsdl_fpi_2003-10-31.xls\n",
      "Processed: nsdl_fpi_2003-11-30.xls\n",
      "Processed: nsdl_fpi_2003-12-31.xls\n",
      "Processed: nsdl_fpi_2004-01-31.xls\n",
      "Processed: nsdl_fpi_2004-02-29.xls\n",
      "Processed: nsdl_fpi_2004-03-31.xls\n",
      "Processed: nsdl_fpi_2004-04-30.xls\n",
      "Processed: nsdl_fpi_2004-05-31.xls\n",
      "Processed: nsdl_fpi_2004-06-30.xls\n",
      "Processed: nsdl_fpi_2004-07-31.xls\n",
      "Processed: nsdl_fpi_2004-08-31.xls\n",
      "Processed: nsdl_fpi_2004-09-30.xls\n",
      "Processed: nsdl_fpi_2004-10-31.xls\n",
      "Processed: nsdl_fpi_2004-11-30.xls\n",
      "Processed: nsdl_fpi_2004-12-31.xls\n",
      "Processed: nsdl_fpi_2005-01-31.xls\n",
      "Processed: nsdl_fpi_2005-02-28.xls\n",
      "Processed: nsdl_fpi_2005-03-31.xls\n",
      "Processed: nsdl_fpi_2005-04-30.xls\n",
      "Processed: nsdl_fpi_2005-05-31.xls\n",
      "Processed: nsdl_fpi_2005-06-30.xls\n",
      "Processed: nsdl_fpi_2005-07-31.xls\n",
      "Processed: nsdl_fpi_2005-08-31.xls\n",
      "Processed: nsdl_fpi_2005-09-30.xls\n",
      "Processed: nsdl_fpi_2005-10-31.xls\n",
      "Processed: nsdl_fpi_2005-11-30.xls\n",
      "Processed: nsdl_fpi_2005-12-31.xls\n",
      "Processed: nsdl_fpi_2006-01-31.xls\n",
      "Processed: nsdl_fpi_2006-02-28.xls\n",
      "Processed: nsdl_fpi_2006-03-31.xls\n",
      "Processed: nsdl_fpi_2006-04-30.xls\n",
      "Processed: nsdl_fpi_2006-05-31.xls\n",
      "Processed: nsdl_fpi_2006-06-30.xls\n",
      "Processed: nsdl_fpi_2006-07-31.xls\n",
      "Processed: nsdl_fpi_2006-08-31.xls\n",
      "Processed: nsdl_fpi_2006-09-30.xls\n",
      "Processed: nsdl_fpi_2006-10-31.xls\n",
      "Processed: nsdl_fpi_2006-11-30.xls\n",
      "Processed: nsdl_fpi_2006-12-31.xls\n",
      "Processed: nsdl_fpi_2007-01-31.xls\n",
      "Processed: nsdl_fpi_2007-02-28.xls\n",
      "Processed: nsdl_fpi_2007-03-31.xls\n",
      "Processed: nsdl_fpi_2007-04-30.xls\n",
      "Processed: nsdl_fpi_2007-05-31.xls\n",
      "Processed: nsdl_fpi_2007-06-30.xls\n",
      "Processed: nsdl_fpi_2007-07-31.xls\n",
      "Processed: nsdl_fpi_2007-08-31.xls\n",
      "Processed: nsdl_fpi_2007-09-30.xls\n",
      "Processed: nsdl_fpi_2007-10-31.xls\n",
      "Processed: nsdl_fpi_2007-11-30.xls\n",
      "Processed: nsdl_fpi_2007-12-31.xls\n",
      "Processed: nsdl_fpi_2008-01-31.xls\n",
      "Processed: nsdl_fpi_2008-02-29.xls\n",
      "Processed: nsdl_fpi_2008-03-31.xls\n",
      "Processed: nsdl_fpi_2008-04-30.xls\n",
      "Processed: nsdl_fpi_2008-05-31.xls\n",
      "Processed: nsdl_fpi_2008-06-30.xls\n",
      "Processed: nsdl_fpi_2008-07-31.xls\n",
      "Processed: nsdl_fpi_2008-08-31.xls\n",
      "Processed: nsdl_fpi_2008-09-30.xls\n",
      "Processed: nsdl_fpi_2008-10-31.xls\n",
      "Processed: nsdl_fpi_2008-11-30.xls\n",
      "Processed: nsdl_fpi_2008-12-31.xls\n",
      "Processed: nsdl_fpi_2009-01-31.xls\n",
      "Processed: nsdl_fpi_2009-02-28.xls\n",
      "Processed: nsdl_fpi_2009-03-31.xls\n",
      "Processed: nsdl_fpi_2009-04-30.xls\n",
      "Processed: nsdl_fpi_2009-05-31.xls\n",
      "Processed: nsdl_fpi_2009-06-30.xls\n",
      "Processed: nsdl_fpi_2009-07-31.xls\n",
      "Processed: nsdl_fpi_2009-08-31.xls\n",
      "Processed: nsdl_fpi_2009-09-30.xls\n",
      "Processed: nsdl_fpi_2009-10-31.xls\n",
      "Processed: nsdl_fpi_2009-11-30.xls\n",
      "\n",
      "Successfully combined 119 files!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporting Date</th>\n",
       "      <th>Debt/Equity</th>\n",
       "      <th>Gross Purchases(Rs Crore)</th>\n",
       "      <th>Gross Sales(Rs Crore)</th>\n",
       "      <th>Net Investment (Rs Crore)</th>\n",
       "      <th>Net Investment US($) million</th>\n",
       "      <th>Conversion (1 USD TO INR)</th>\n",
       "      <th>nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-Jan-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>148.40</td>\n",
       "      <td>59.30</td>\n",
       "      <td>89.10</td>\n",
       "      <td>20.50</td>\n",
       "      <td>Rs. 43.52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>333.40</td>\n",
       "      <td>238.20</td>\n",
       "      <td>95.20</td>\n",
       "      <td>21.90</td>\n",
       "      <td>Rs. 43.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>250.30</td>\n",
       "      <td>528.30</td>\n",
       "      <td>(278.00)</td>\n",
       "      <td>(63.90)</td>\n",
       "      <td>Rs. 43.52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>269.00</td>\n",
       "      <td>559.70</td>\n",
       "      <td>(290.70)</td>\n",
       "      <td>(66.80)</td>\n",
       "      <td>Rs. 43.52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-Jan-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>259.50</td>\n",
       "      <td>223.10</td>\n",
       "      <td>36.40</td>\n",
       "      <td>8.40</td>\n",
       "      <td>Rs. 43.51</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>02-Aug-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>158.20</td>\n",
       "      <td>236.00</td>\n",
       "      <td>(77.80)</td>\n",
       "      <td>(17.20)</td>\n",
       "      <td>Rs. 45.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>03-Aug-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>84.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>(6.00)</td>\n",
       "      <td>(1.30)</td>\n",
       "      <td>Rs. 45.34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>04-Aug-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>287.90</td>\n",
       "      <td>241.20</td>\n",
       "      <td>46.70</td>\n",
       "      <td>10.30</td>\n",
       "      <td>Rs. 45.44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>07-Aug-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>269.70</td>\n",
       "      <td>163.80</td>\n",
       "      <td>105.90</td>\n",
       "      <td>23.10</td>\n",
       "      <td>Rs. 45.79</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>08-Aug-2000</td>\n",
       "      <td>Equity</td>\n",
       "      <td>157.30</td>\n",
       "      <td>79.10</td>\n",
       "      <td>78.20</td>\n",
       "      <td>17.20</td>\n",
       "      <td>Rs. 45.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Reporting Date Debt/Equity Gross Purchases(Rs Crore)  \\\n",
       "0      04-Jan-2000      Equity                    148.40   \n",
       "1      05-Jan-2000      Equity                    333.40   \n",
       "2      06-Jan-2000      Equity                    250.30   \n",
       "3      07-Jan-2000      Equity                    269.00   \n",
       "4      10-Jan-2000      Equity                    259.50   \n",
       "..             ...         ...                       ...   \n",
       "145    02-Aug-2000      Equity                    158.20   \n",
       "146    03-Aug-2000      Equity                     84.00   \n",
       "147    04-Aug-2000      Equity                    287.90   \n",
       "148    07-Aug-2000      Equity                    269.70   \n",
       "149    08-Aug-2000      Equity                    157.30   \n",
       "\n",
       "    Gross Sales(Rs Crore) Net Investment (Rs Crore)  \\\n",
       "0                   59.30                     89.10   \n",
       "1                  238.20                     95.20   \n",
       "2                  528.30                  (278.00)   \n",
       "3                  559.70                  (290.70)   \n",
       "4                  223.10                     36.40   \n",
       "..                    ...                       ...   \n",
       "145                236.00                   (77.80)   \n",
       "146                 90.00                    (6.00)   \n",
       "147                241.20                     46.70   \n",
       "148                163.80                    105.90   \n",
       "149                 79.10                     78.20   \n",
       "\n",
       "    Net Investment US($) million Conversion (1 USD TO INR)  nan  \n",
       "0                          20.50                 Rs. 43.52  NaN  \n",
       "1                          21.90                 Rs. 43.50  NaN  \n",
       "2                        (63.90)                 Rs. 43.52  NaN  \n",
       "3                        (66.80)                 Rs. 43.52  NaN  \n",
       "4                           8.40                 Rs. 43.51  NaN  \n",
       "..                           ...                       ...  ...  \n",
       "145                      (17.20)                 Rs. 45.13  NaN  \n",
       "146                       (1.30)                 Rs. 45.34  NaN  \n",
       "147                        10.30                 Rs. 45.44  NaN  \n",
       "148                        23.10                 Rs. 45.79  NaN  \n",
       "149                        17.20                 Rs. 45.57  NaN  \n",
       "\n",
       "[150 rows x 8 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1. Set your specific Windows folder path\n",
    "# The 'r' before the string handles the Windows backslashes correctly\n",
    "path = r\"C:\\Users\\patel\\OneDrive\\Desktop\\Code\\downloads\\before 2010\"\n",
    "file_list = glob.glob(os.path.join(path, \"*.xls\"))\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    try:\n",
    "        # Use read_html as these are actually HTML files with .xls extensions\n",
    "        tables = pd.read_html(file_path)\n",
    "        df_investments = tables[0]\n",
    "        \n",
    "        # Hardcode the column names (adjusted for the usual artifact column in these NSDL files)\n",
    "        num_cols = len(df_investments.columns)\n",
    "        headers = [\n",
    "            'Reporting Date', \n",
    "            'Debt/Equity', \n",
    "            'Gross Purchases(Rs Crore)', \n",
    "            'Gross Sales(Rs Crore)', \n",
    "            'Net Investment (Rs Crore)', \n",
    "            'Net Investment US($) million', \n",
    "            'Conversion (1 USD TO INR)',\n",
    "            'nan'\n",
    "        ]\n",
    "        \n",
    "        # If the file has a 9th empty column (common in these scrapes), name it 'nan'\n",
    "        if num_cols > len(headers):\n",
    "            headers += ['nan'] * (num_cols - len(headers))\n",
    "        \n",
    "        df_investments.columns = headers\n",
    "        \n",
    "        # Cleaning logic based on your code\n",
    "        # We slice from index 3 to skip the HTML disclaimer and header rows\n",
    "        df_clean = df_investments.iloc[0:].reset_index(drop=True)\n",
    "        \n",
    "        # Fill the merged date cells\n",
    "        df_clean['Reporting Date'] = df_clean['Reporting Date'].ffill()\n",
    "        \n",
    "        # Filter for Equity only\n",
    "        df_equity_only = df_clean[df_clean['Debt/Equity'] == 'Equity'].copy()\n",
    "        \n",
    "        # Remove the bottom 3 rows (Sub-totals/Notes)\n",
    "    #    df_equity_only = df_equity_only.iloc[:-3]\n",
    "        # 1. Clean the 'Reporting Date' column of hidden junk (newlines, tabs, extra spaces)\n",
    "        df_equity_only['Reporting Date'] = df_equity_only['Reporting Date'].astype(str).str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "        # 2. Convert to datetime, but COERCE errors to NaN\n",
    "        # This turns \"Total for Month\", \"Notes\", etc. into NaN\n",
    "        valid_dates = pd.to_datetime(df_equity_only['Reporting Date'], errors='coerce')\n",
    "\n",
    "        # 3. Filter: Keep only rows where 'Reporting Date' is NOT NaN\n",
    "        df_equity_only = df_equity_only[valid_dates.notna()].copy()\n",
    "            \n",
    "        all_dfs.append(df_equity_only)\n",
    "        print(f\"Processed: {os.path.basename(file_path)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {os.path.basename(file_path)} due to error: {e}\")\n",
    "\n",
    "# 2. Combine all files into one master DataFrame\n",
    "if all_dfs:\n",
    "    final_combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"\\nSuccessfully combined {len(all_dfs)} files!\")\n",
    "    \n",
    "    # Optional: Save the final result to your desktop\n",
    "    # final_combined_df.to_csv(os.path.join(path, \"combined_equity_data.csv\"), index=False)\n",
    "else:\n",
    "    print(\"No files were processed. Check if the folder path is correct and contains .xls files.\")\n",
    "\n",
    "final_combined_df.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eee6313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUCCESS ---\n",
      "File saved to: C:/Users/patel/OneDrive/Desktop/Code/fpi_data\\combined_equity_data_2009.csv\n",
      "Total rows saved: 2462\n"
     ]
    }
   ],
   "source": [
    "# Define the output file name\n",
    "output_filename = \"combined_equity_data_2009.csv\"\n",
    "output_path = os.path.join(\"C:/Users/patel/OneDrive/Desktop/Code/fpi_data\", output_filename)\n",
    "\n",
    "# Save the combined DataFrame\n",
    "if not final_combined_df.empty:\n",
    "    # index=False prevents pandas from adding an extra column with row numbers\n",
    "    final_combined_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Alternatively, for Excel:\n",
    "    # final_combined_df.to_excel(output_path.replace(\".csv\", \".xlsx\"), index=False)\n",
    "    \n",
    "    print(f\"--- SUCCESS ---\")\n",
    "    print(f\"File saved to: {output_path}\")\n",
    "    print(f\"Total rows saved: {len(final_combined_df)}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty. Nothing to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fed168f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: nsdl_fpi_2009-12-31.xls\n",
      "Processed: nsdl_fpi_2010-01-31.xls\n",
      "Processed: nsdl_fpi_2010-02-28.xls\n",
      "Processed: nsdl_fpi_2010-03-31.xls\n",
      "Processed: nsdl_fpi_2010-04-30.xls\n",
      "Processed: nsdl_fpi_2010-05-31.xls\n",
      "Processed: nsdl_fpi_2010-06-30.xls\n",
      "Processed: nsdl_fpi_2010-07-31.xls\n",
      "Processed: nsdl_fpi_2010-08-31.xls\n",
      "Processed: nsdl_fpi_2010-09-30.xls\n",
      "Processed: nsdl_fpi_2010-10-31.xls\n",
      "Processed: nsdl_fpi_2010-11-30.xls\n",
      "Processed: nsdl_fpi_2010-12-31.xls\n",
      "Processed: nsdl_fpi_2011-01-31.xls\n",
      "Processed: nsdl_fpi_2011-02-28.xls\n",
      "Processed: nsdl_fpi_2011-03-31.xls\n",
      "Processed: nsdl_fpi_2011-04-30.xls\n",
      "Processed: nsdl_fpi_2011-05-31.xls\n",
      "Processed: nsdl_fpi_2011-06-30.xls\n",
      "Processed: nsdl_fpi_2011-07-31.xls\n",
      "Processed: nsdl_fpi_2011-08-31.xls\n",
      "Processed: nsdl_fpi_2011-09-30.xls\n",
      "Processed: nsdl_fpi_2011-10-31.xls\n",
      "Processed: nsdl_fpi_2011-11-30.xls\n",
      "Processed: nsdl_fpi_2011-12-31.xls\n",
      "Processed: nsdl_fpi_2012-01-31.xls\n",
      "Processed: nsdl_fpi_2012-02-29.xls\n",
      "Processed: nsdl_fpi_2012-03-31.xls\n",
      "Processed: nsdl_fpi_2012-04-30.xls\n",
      "Processed: nsdl_fpi_2012-05-31.xls\n",
      "Processed: nsdl_fpi_2012-06-30.xls\n",
      "Processed: nsdl_fpi_2012-07-31.xls\n",
      "Processed: nsdl_fpi_2012-08-31.xls\n",
      "Processed: nsdl_fpi_2012-09-30.xls\n",
      "Processed: nsdl_fpi_2012-10-31.xls\n",
      "Processed: nsdl_fpi_2012-11-30.xls\n",
      "Processed: nsdl_fpi_2012-12-31.xls\n",
      "Processed: nsdl_fpi_2013-01-31.xls\n",
      "Processed: nsdl_fpi_2013-02-28.xls\n",
      "Processed: nsdl_fpi_2013-03-31.xls\n",
      "Processed: nsdl_fpi_2013-04-30.xls\n",
      "Processed: nsdl_fpi_2013-05-31.xls\n",
      "Processed: nsdl_fpi_2013-06-30.xls\n",
      "Processed: nsdl_fpi_2013-07-31.xls\n",
      "Processed: nsdl_fpi_2013-08-31.xls\n",
      "Processed: nsdl_fpi_2013-09-30.xls\n",
      "Processed: nsdl_fpi_2013-10-31.xls\n",
      "Processed: nsdl_fpi_2013-11-30.xls\n",
      "Processed: nsdl_fpi_2013-12-31.xls\n",
      "Processed: nsdl_fpi_2014-01-31.xls\n",
      "Processed: nsdl_fpi_2014-02-28.xls\n",
      "Processed: nsdl_fpi_2014-03-31.xls\n",
      "Processed: nsdl_fpi_2014-04-30.xls\n",
      "Processed: nsdl_fpi_2014-05-31.xls\n",
      "Processed: nsdl_fpi_2014-06-30.xls\n",
      "Processed: nsdl_fpi_2014-07-31.xls\n",
      "Processed: nsdl_fpi_2014-08-31.xls\n",
      "Processed: nsdl_fpi_2014-09-30.xls\n",
      "Processed: nsdl_fpi_2014-10-31.xls\n",
      "Processed: nsdl_fpi_2014-11-30.xls\n",
      "Processed: nsdl_fpi_2014-12-31.xls\n",
      "Processed: nsdl_fpi_2015-01-31.xls\n",
      "Processed: nsdl_fpi_2015-02-28.xls\n",
      "Processed: nsdl_fpi_2015-03-31.xls\n",
      "Processed: nsdl_fpi_2015-04-30.xls\n",
      "Processed: nsdl_fpi_2015-05-31.xls\n",
      "Processed: nsdl_fpi_2015-06-30.xls\n",
      "Processed: nsdl_fpi_2015-07-31.xls\n",
      "Processed: nsdl_fpi_2015-08-31.xls\n",
      "Processed: nsdl_fpi_2015-09-30.xls\n",
      "Processed: nsdl_fpi_2015-10-31.xls\n",
      "Processed: nsdl_fpi_2015-11-30.xls\n",
      "Processed: nsdl_fpi_2015-12-31.xls\n",
      "Processed: nsdl_fpi_2016-01-31.xls\n",
      "Processed: nsdl_fpi_2016-02-29.xls\n",
      "Processed: nsdl_fpi_2016-03-31.xls\n",
      "Processed: nsdl_fpi_2016-04-30.xls\n",
      "Processed: nsdl_fpi_2016-05-31.xls\n",
      "Processed: nsdl_fpi_2016-06-30.xls\n",
      "Processed: nsdl_fpi_2016-07-31.xls\n",
      "Processed: nsdl_fpi_2016-08-31.xls\n",
      "Processed: nsdl_fpi_2016-09-30.xls\n",
      "Processed: nsdl_fpi_2016-10-31.xls\n",
      "Processed: nsdl_fpi_2016-11-30.xls\n",
      "Processed: nsdl_fpi_2016-12-31.xls\n",
      "Processed: nsdl_fpi_2017-01-31.xls\n",
      "Processed: nsdl_fpi_2017-02-28.xls\n",
      "Processed: nsdl_fpi_2017-03-31.xls\n",
      "Processed: nsdl_fpi_2017-04-30.xls\n",
      "Processed: nsdl_fpi_2017-05-31.xls\n",
      "Processed: nsdl_fpi_2017-06-30.xls\n",
      "Processed: nsdl_fpi_2017-07-31.xls\n",
      "Processed: nsdl_fpi_2017-08-31.xls\n",
      "Processed: nsdl_fpi_2017-09-30.xls\n",
      "Processed: nsdl_fpi_2017-10-31.xls\n",
      "Processed: nsdl_fpi_2017-11-30.xls\n",
      "Processed: nsdl_fpi_2017-12-31.xls\n",
      "Processed: nsdl_fpi_2018-01-31.xls\n",
      "Processed: nsdl_fpi_2018-02-28.xls\n",
      "Processed: nsdl_fpi_2018-03-31.xls\n",
      "Processed: nsdl_fpi_2018-04-30.xls\n",
      "Processed: nsdl_fpi_2018-05-31.xls\n",
      "Processed: nsdl_fpi_2018-06-30.xls\n",
      "Processed: nsdl_fpi_2018-07-31.xls\n",
      "Processed: nsdl_fpi_2018-08-31.xls\n",
      "Processed: nsdl_fpi_2018-09-30.xls\n",
      "Processed: nsdl_fpi_2018-10-31.xls\n",
      "Processed: nsdl_fpi_2018-11-30.xls\n",
      "Processed: nsdl_fpi_2018-12-31.xls\n",
      "Processed: nsdl_fpi_2019-01-31.xls\n",
      "Processed: nsdl_fpi_2019-02-28.xls\n",
      "Processed: nsdl_fpi_2019-03-31.xls\n",
      "Processed: nsdl_fpi_2019-04-30.xls\n",
      "Processed: nsdl_fpi_2019-05-31.xls\n",
      "Processed: nsdl_fpi_2019-06-30.xls\n",
      "Processed: nsdl_fpi_2019-07-31.xls\n",
      "Processed: nsdl_fpi_2019-08-31.xls\n",
      "Processed: nsdl_fpi_2019-09-30.xls\n",
      "Processed: nsdl_fpi_2019-10-31.xls\n",
      "Processed: nsdl_fpi_2019-11-30.xls\n",
      "Processed: nsdl_fpi_2019-12-31.xls\n",
      "Processed: nsdl_fpi_2020-01-31.xls\n",
      "Processed: nsdl_fpi_2020-02-29.xls\n",
      "Processed: nsdl_fpi_2020-03-31.xls\n",
      "Processed: nsdl_fpi_2020-04-30.xls\n",
      "Processed: nsdl_fpi_2020-05-31.xls\n",
      "Processed: nsdl_fpi_2020-06-30.xls\n",
      "Processed: nsdl_fpi_2020-07-31.xls\n",
      "Processed: nsdl_fpi_2020-08-31.xls\n",
      "Processed: nsdl_fpi_2020-09-30.xls\n",
      "Processed: nsdl_fpi_2020-10-31.xls\n",
      "Processed: nsdl_fpi_2020-11-30.xls\n",
      "Processed: nsdl_fpi_2020-12-31.xls\n",
      "Processed: nsdl_fpi_2021-01-31.xls\n",
      "Processed: nsdl_fpi_2021-02-28.xls\n",
      "Processed: nsdl_fpi_2021-03-31.xls\n",
      "Processed: nsdl_fpi_2021-04-30.xls\n",
      "Processed: nsdl_fpi_2021-05-31.xls\n",
      "Processed: nsdl_fpi_2021-06-30.xls\n",
      "Processed: nsdl_fpi_2021-07-31.xls\n",
      "Processed: nsdl_fpi_2021-08-31.xls\n",
      "Processed: nsdl_fpi_2021-09-30.xls\n",
      "Processed: nsdl_fpi_2021-10-31.xls\n",
      "Processed: nsdl_fpi_2021-11-30.xls\n",
      "Processed: nsdl_fpi_2021-12-31.xls\n",
      "Processed: nsdl_fpi_2022-01-31.xls\n",
      "Processed: nsdl_fpi_2022-02-28.xls\n",
      "Processed: nsdl_fpi_2022-03-31.xls\n",
      "Processed: nsdl_fpi_2022-04-30.xls\n",
      "Processed: nsdl_fpi_2022-05-31.xls\n",
      "Processed: nsdl_fpi_2022-06-30.xls\n",
      "Processed: nsdl_fpi_2022-07-31.xls\n",
      "Processed: nsdl_fpi_2022-08-31.xls\n",
      "Processed: nsdl_fpi_2022-09-30.xls\n",
      "Processed: nsdl_fpi_2022-10-31.xls\n",
      "Processed: nsdl_fpi_2022-11-30.xls\n",
      "Processed: nsdl_fpi_2022-12-31.xls\n",
      "Processed: nsdl_fpi_2023-01-31.xls\n",
      "Processed: nsdl_fpi_2023-02-28.xls\n",
      "Processed: nsdl_fpi_2023-03-31.xls\n",
      "Processed: nsdl_fpi_2023-04-30.xls\n",
      "Processed: nsdl_fpi_2023-05-31.xls\n",
      "Processed: nsdl_fpi_2023-06-30.xls\n",
      "Processed: nsdl_fpi_2023-07-31.xls\n",
      "Processed: nsdl_fpi_2023-08-31.xls\n",
      "Processed: nsdl_fpi_2023-09-30.xls\n",
      "Processed: nsdl_fpi_2023-10-31.xls\n",
      "Processed: nsdl_fpi_2023-11-30.xls\n",
      "Processed: nsdl_fpi_2023-12-31.xls\n",
      "Processed: nsdl_fpi_2024-01-31.xls\n",
      "Processed: nsdl_fpi_2024-02-29.xls\n",
      "Processed: nsdl_fpi_2024-03-31.xls\n",
      "Processed: nsdl_fpi_2024-04-30.xls\n",
      "Processed: nsdl_fpi_2024-05-31.xls\n",
      "Processed: nsdl_fpi_2024-06-30.xls\n",
      "Processed: nsdl_fpi_2024-07-31.xls\n",
      "Processed: nsdl_fpi_2024-08-31.xls\n",
      "Processed: nsdl_fpi_2024-09-30.xls\n",
      "Processed: nsdl_fpi_2024-10-31.xls\n",
      "Processed: nsdl_fpi_2024-11-30.xls\n",
      "Processed: nsdl_fpi_2024-12-31.xls\n",
      "Processed: nsdl_fpi_2025-01-31.xls\n",
      "Processed: nsdl_fpi_2025-02-28.xls\n",
      "Processed: nsdl_fpi_2025-03-31.xls\n",
      "Processed: nsdl_fpi_2025-04-30.xls\n",
      "Processed: nsdl_fpi_2025-05-31.xls\n",
      "Processed: nsdl_fpi_2025-06-30.xls\n",
      "Processed: nsdl_fpi_2025-07-31.xls\n",
      "Processed: nsdl_fpi_2025-08-31.xls\n",
      "Processed: nsdl_fpi_2025-09-30.xls\n",
      "Processed: nsdl_fpi_2025-10-31.xls\n",
      "Processed: nsdl_fpi_2025-11-30.xls\n",
      "Processed: nsdl_fpi_2025-12-31.xls\n",
      "Processed: nsdl_fpi_2026-01-30.xls\n",
      "\n",
      "Successfully combined 194 files!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reporting Date</th>\n",
       "      <th>Debt/Equity</th>\n",
       "      <th>Investment Route</th>\n",
       "      <th>Gross Purchases(Rs Crore)</th>\n",
       "      <th>Gross Sales(Rs Crore)</th>\n",
       "      <th>Net Investment (Rs Crore)</th>\n",
       "      <th>Net Investment US($) million</th>\n",
       "      <th>Conversion (1 USD TO INR)</th>\n",
       "      <th>nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-Dec-2009</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Stock Exchange</td>\n",
       "      <td>2812.30</td>\n",
       "      <td>2274.70</td>\n",
       "      <td>537.50</td>\n",
       "      <td>115.64</td>\n",
       "      <td>Rs.46.4800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-Dec-2009</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Primary market &amp; others</td>\n",
       "      <td>163.80</td>\n",
       "      <td>1.50</td>\n",
       "      <td>162.30</td>\n",
       "      <td>34.92</td>\n",
       "      <td>Rs.46.4800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-Dec-2009</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Sub-total</td>\n",
       "      <td>2976.10</td>\n",
       "      <td>2276.20</td>\n",
       "      <td>699.80</td>\n",
       "      <td>150.57</td>\n",
       "      <td>Rs.46.4800</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-Dec-2009</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Stock Exchange</td>\n",
       "      <td>2987.30</td>\n",
       "      <td>2237.80</td>\n",
       "      <td>749.50</td>\n",
       "      <td>161.35</td>\n",
       "      <td>Rs.46.4500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02-Dec-2009</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Primary market &amp; others</td>\n",
       "      <td>1561.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1560.40</td>\n",
       "      <td>335.94</td>\n",
       "      <td>Rs.46.4500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>11-Feb-2010</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Primary market &amp; others</td>\n",
       "      <td>13.60</td>\n",
       "      <td>28.70</td>\n",
       "      <td>(15.10)</td>\n",
       "      <td>(3.24)</td>\n",
       "      <td>Rs.46.5600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>11-Feb-2010</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Sub-total</td>\n",
       "      <td>2376.80</td>\n",
       "      <td>2400.40</td>\n",
       "      <td>(23.60)</td>\n",
       "      <td>(5.07)</td>\n",
       "      <td>Rs.46.5600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>15-Feb-2010</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Stock Exchange</td>\n",
       "      <td>1775.60</td>\n",
       "      <td>1457.90</td>\n",
       "      <td>317.60</td>\n",
       "      <td>68.37</td>\n",
       "      <td>Rs.46.4600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>15-Feb-2010</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Primary market &amp; others</td>\n",
       "      <td>33.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.30</td>\n",
       "      <td>7.17</td>\n",
       "      <td>Rs.46.4600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>15-Feb-2010</td>\n",
       "      <td>Equity</td>\n",
       "      <td>Sub-total</td>\n",
       "      <td>1808.90</td>\n",
       "      <td>1458.00</td>\n",
       "      <td>350.90</td>\n",
       "      <td>75.54</td>\n",
       "      <td>Rs.46.4600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Reporting Date Debt/Equity         Investment Route  \\\n",
       "0      01-Dec-2009      Equity           Stock Exchange   \n",
       "1      01-Dec-2009      Equity  Primary market & others   \n",
       "2      01-Dec-2009      Equity                Sub-total   \n",
       "3      02-Dec-2009      Equity           Stock Exchange   \n",
       "4      02-Dec-2009      Equity  Primary market & others   \n",
       "..             ...         ...                      ...   \n",
       "145    11-Feb-2010      Equity  Primary market & others   \n",
       "146    11-Feb-2010      Equity                Sub-total   \n",
       "147    15-Feb-2010      Equity           Stock Exchange   \n",
       "148    15-Feb-2010      Equity  Primary market & others   \n",
       "149    15-Feb-2010      Equity                Sub-total   \n",
       "\n",
       "    Gross Purchases(Rs Crore) Gross Sales(Rs Crore) Net Investment (Rs Crore)  \\\n",
       "0                     2812.30               2274.70                    537.50   \n",
       "1                      163.80                  1.50                    162.30   \n",
       "2                     2976.10               2276.20                    699.80   \n",
       "3                     2987.30               2237.80                    749.50   \n",
       "4                     1561.50                  1.00                   1560.40   \n",
       "..                        ...                   ...                       ...   \n",
       "145                     13.60                 28.70                   (15.10)   \n",
       "146                   2376.80               2400.40                   (23.60)   \n",
       "147                   1775.60               1457.90                    317.60   \n",
       "148                     33.30                  0.00                     33.30   \n",
       "149                   1808.90               1458.00                    350.90   \n",
       "\n",
       "    Net Investment US($) million Conversion (1 USD TO INR)  nan  \n",
       "0                         115.64                Rs.46.4800  NaN  \n",
       "1                          34.92                Rs.46.4800  NaN  \n",
       "2                         150.57                Rs.46.4800  NaN  \n",
       "3                         161.35                Rs.46.4500  NaN  \n",
       "4                         335.94                Rs.46.4500  NaN  \n",
       "..                           ...                       ...  ...  \n",
       "145                       (3.24)                Rs.46.5600  NaN  \n",
       "146                       (5.07)                Rs.46.5600  NaN  \n",
       "147                        68.37                Rs.46.4600  NaN  \n",
       "148                         7.17                Rs.46.4600  NaN  \n",
       "149                        75.54                Rs.46.4600  NaN  \n",
       "\n",
       "[150 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1. Set your specific Windows folder path\n",
    "# The 'r' before the string handles the Windows backslashes correctly\n",
    "path = r\"C:\\Users\\patel\\OneDrive\\Desktop\\Code\\downloads\"\n",
    "file_list = glob.glob(os.path.join(path, \"*.xls\"))\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for file_path in file_list:\n",
    "    try:\n",
    "        # Use read_html as these are actually HTML files with .xls extensions\n",
    "        tables = pd.read_html(file_path)\n",
    "        df_investments = tables[0]\n",
    "        \n",
    "        # Hardcode the column names (adjusted for the usual artifact column in these NSDL files)\n",
    "        num_cols = len(df_investments.columns)\n",
    "        headers = [\n",
    "            'Reporting Date', \n",
    "            'Debt/Equity', \n",
    "            'Investment Route', \n",
    "            'Gross Purchases(Rs Crore)', \n",
    "            'Gross Sales(Rs Crore)', \n",
    "            'Net Investment (Rs Crore)', \n",
    "            'Net Investment US($) million', \n",
    "            'Conversion (1 USD TO INR)',\n",
    "            'nan'\n",
    "        ]\n",
    "        \n",
    "        # If the file has a 9th empty column (common in these scrapes), name it 'nan'\n",
    "        if num_cols > len(headers):\n",
    "            headers += ['nan'] * (num_cols - len(headers))\n",
    "        \n",
    "        df_investments.columns = headers\n",
    "        \n",
    "        # Cleaning logic based on your code\n",
    "        # We slice from index 3 to skip the HTML disclaimer and header rows\n",
    "        df_clean = df_investments.iloc[0:].reset_index(drop=True)\n",
    "        \n",
    "        # Fill the merged date cells\n",
    "        df_clean['Reporting Date'] = df_clean['Reporting Date'].ffill()\n",
    "        \n",
    "        # Filter for Equity only\n",
    "        df_equity_only = df_clean[df_clean['Debt/Equity'] == 'Equity'].copy()\n",
    "        \n",
    "        # Remove the bottom 3 rows (Sub-totals/Notes)\n",
    "    #    df_equity_only = df_equity_only.iloc[:-3]\n",
    "        # 1. Clean the 'Reporting Date' column of hidden junk (newlines, tabs, extra spaces)\n",
    "        df_equity_only['Reporting Date'] = df_equity_only['Reporting Date'].astype(str).str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "        # 2. Convert to datetime, but COERCE errors to NaN\n",
    "        # This turns \"Total for Month\", \"Notes\", etc. into NaN\n",
    "        valid_dates = pd.to_datetime(df_equity_only['Reporting Date'], errors='coerce')\n",
    "\n",
    "        # 3. Filter: Keep only rows where 'Reporting Date' is NOT NaN\n",
    "        df_equity_only = df_equity_only[valid_dates.notna()].copy()\n",
    "            \n",
    "        all_dfs.append(df_equity_only)\n",
    "        print(f\"Processed: {os.path.basename(file_path)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {os.path.basename(file_path)} due to error: {e}\")\n",
    "\n",
    "# 2. Combine all files into one master DataFrame\n",
    "if all_dfs:\n",
    "    final_combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(f\"\\nSuccessfully combined {len(all_dfs)} files!\")\n",
    "    \n",
    "    # Optional: Save the final result to your desktop\n",
    "    # final_combined_df.to_csv(os.path.join(path, \"combined_equity_data.csv\"), index=False)\n",
    "else:\n",
    "    print(\"No files were processed. Check if the folder path is correct and contains .xls files.\")\n",
    "\n",
    "final_combined_df.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e47d1de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUCCESS ---\n",
      "File saved to: C:/Users/patel/OneDrive/Desktop/Code/fpi_data\\combined_equity_data_2010.csv\n",
      "Total rows saved: 11685\n"
     ]
    }
   ],
   "source": [
    "# Define the output file name\n",
    "output_filename = \"combined_equity_data_2010.csv\"\n",
    "output_path = os.path.join(\"C:/Users/patel/OneDrive/Desktop/Code/fpi_data\", output_filename)\n",
    "\n",
    "# Save the combined DataFrame\n",
    "if not final_combined_df.empty:\n",
    "    # index=False prevents pandas from adding an extra column with row numbers\n",
    "    final_combined_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    # Alternatively, for Excel:\n",
    "    # final_combined_df.to_excel(output_path.replace(\".csv\", \".xlsx\"), index=False)\n",
    "    \n",
    "    print(f\"--- SUCCESS ---\")\n",
    "    print(f\"File saved to: {output_path}\")\n",
    "    print(f\"Total rows saved: {len(final_combined_df)}\")\n",
    "else:\n",
    "    print(\"DataFrame is empty. Nothing to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd74666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use read_html instead of read_excel\n",
    "file_path = \"/content/nsdl_fpi_2009-11-30.xls\"\n",
    "tables = pd.read_html(file_path)\n",
    "\n",
    "# tables is a list. Based on your data:\n",
    "# tables[0] should be the FPI Investment table\n",
    "# tables[1] should be the FPI Derivative Trades table\n",
    "\n",
    "df_investments = tables[0]\n",
    "df_clean = df_investments\n",
    "df_clean.columns = df_clean.iloc[0] # Set the first row as columns\n",
    "# Hardcode the column names exactly as they appear in the table\n",
    "df_investments.columns = [\n",
    "    'Reporting Date',\n",
    "    'Debt/Equity',\n",
    "    'Investment Route',\n",
    "    'Gross Purchases(Rs Crore)',\n",
    "    'Gross Sales(Rs Crore)',\n",
    "    'Net Investment (Rs Crore)',\n",
    "    'Net Investment US($) million',\n",
    "    'Conversion (1 USD TO INR)',\n",
    " #   'nan'\n",
    "]\n",
    "\n",
    "# Drop the first 3 rows (disclaimer text and the original header rows)\n",
    "df_clean = df_investments.iloc[0:].reset_index(drop=True)\n",
    "#df_clean.drop(columns=['nan'], inplace=True)\n",
    "df_clean['Reporting Date'] = df_clean['Reporting Date'].ffill()\n",
    "df_equity_only = df_clean[df_clean['Debt/Equity'] == 'Equity'].copy()\n",
    "df_equity_only = df_equity_only.iloc[:-3]\n",
    "df_equity_only.head(150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your file\n",
    "df = pd.read_csv('/content/combined_equity_data_2010.csv')\n",
    "\n",
    "# Filter the dataframe\n",
    "# We use == to keep only the 'Stock Exchange' entries\n",
    "filtered_df = df[df['Investment Route'] == 'Stock Exchange']\n",
    "\n",
    "# Save the cleaned version\n",
    "#filtered_df.to_csv('filtered_data.csv', index=False)\n",
    "\n",
    "filtered_df.head(100)\n",
    "\n",
    "filtered_df = filtered_df.drop(columns=['Investment Route'])\n",
    "\n",
    "filtered_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12791d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load your existing CSV file\n",
    "# Replace this path if your file is located elsewhere\n",
    "other_df_path = '/content/combined_equity_data_2009.csv'\n",
    "other_df = pd.read_csv(other_df_path)\n",
    "\n",
    "# 3. Combine (concatenate) the two DataFrames\n",
    "# ignore_index=True ensures the row numbers are reset and continuous\n",
    "final_combined_df = pd.concat([other_df, filtered_df], ignore_index=True)\n",
    "\n",
    "# 4. Save the combined result\n",
    "final_combined_df.to_csv('combined_fpi_equity_data.csv', index=False)\n",
    "\n",
    "print(\"Data combined successfully! First 5 rows of the new dataset:\")\n",
    "print(final_combined_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
